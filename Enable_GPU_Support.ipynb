{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Enable GPU Support.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarwaAllam/Colab/blob/master/Enable_GPU_Support.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "1mc4FhWKqGrM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Enable GPU Support\n"
      ]
    },
    {
      "metadata": {
        "id": "SXJQHzb7qHF2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook was created as part of a webinar. You can check the Webinar here - https://www.youtube.com/watch?v=Gblg8FMUn9k\n",
        "\n",
        "If you need any help, feel free to contact me on Slack. My slack id is **avinashss**"
      ]
    },
    {
      "metadata": {
        "id": "Nxu-tiFJqMAx",
        "colab_type": "code",
        "outputId": "dcd04def-4dad-49ba-9d60-b0a97f01ec04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# google colab does not come with torch installed. And also, in course we are using torch 0.4. \n",
        "# so following snippet of code installs the relevant version\n",
        "\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x577e4000 @  0x7fe4dd9b22a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gQ9vFTBqvGoS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "frvlcNQkvJ__",
        "colab_type": "code",
        "outputId": "8fbe2f03-1c3d-4001-ff5b-4b23af81eed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# we will verify that GPU is enabled for this notebook\n",
        "# following should print: CUDA is available!  Training on GPU ...\n",
        "# \n",
        "# if it prints otherwise, then you need to enable GPU: \n",
        "# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}